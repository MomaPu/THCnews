import asyncio
import os
import sys
import json
from datetime import datetime, timedelta, timezone
from telethon import TelegramClient
from telethon.errors import MsgIdInvalidError
from telethon.tl.types import PeerUser, PeerChannel, PeerChat
from dotenv import load_dotenv

from app.bot.core import save_bad_comment

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))
sys.path.append(root_dir)

# –ò–º–ø–æ—Ä—Ç—ã –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—É—Ç–∏
from app import create_app
from app.database import db
from app.models.models import NewsSource, NewsPost, PostComment
from app.services.texteditor import classify_text

load_dotenv()


API_ID = 20304623
API_HASH = "c1622024c0ad17c26fbd6b34f1d9ef1c"


class TelegramService:
	def __init__(self):
		self.client = TelegramClient(
			'read_client',
			API_ID,
			API_HASH,
			device_model='Iphone 5',
			system_version='IOS 13',
		)


	def _serialize_peer(self, peer):
		"""–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç Peer –æ–±—ä–µ–∫—Ç—ã –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
		if isinstance(peer, PeerUser):
			return {'type': 'user', 'user_id': peer.user_id}
		elif isinstance(peer, PeerChannel):
			return {'type': 'channel', 'channel_id': peer.channel_id}
		elif isinstance(peer, PeerChat):
			return {'type': 'chat', 'chat_id': peer.chat_id}
		elif hasattr(peer, 'user_id'):
			return {'type': 'user', 'user_id': peer.user_id}
		elif hasattr(peer, 'channel_id'):
			return {'type': 'channel', 'channel_id': peer.channel_id}
		elif hasattr(peer, 'chat_id'):
			return {'type': 'chat', 'chat_id': peer.chat_id}
		return str(peer)

	def _serialize_message_replies(self, replies):
		"""–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç MessageReplies –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Å–ª–æ–≤–∞—Ä—å"""
		if not replies:
			return {}
		return {
			'replies': replies.replies,
			'replies_pts': replies.replies_pts,
			'comments': replies.comments,
			'recent_repliers': [self._serialize_peer(user_id) for user_id in
								replies.recent_repliers] if replies.recent_repliers else [],
			'channel_id': self._serialize_peer(replies.channel_id) if replies.channel_id else None,
			'max_id': replies.max_id,
			'read_max_id': replies.read_max_id
		}

	def _serialize_platform_data(self, message):
		"""–°–æ–∑–¥–∞–µ—Ç —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Å–ª–æ–≤–∞—Ä—å platform_data"""
		platform_data = {
			'views': getattr(message, 'views', 0),
			'forwards': getattr(message, 'forwards', 0),
		}

		# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º replies
		if hasattr(message, 'replies') and message.replies:
			platform_data['replies'] = self._serialize_message_replies(message.replies)
		else:
			platform_data['replies'] = {}

		return platform_data

	def _serialize_comment_platform_data(self, comment):
		"""–°–æ–∑–¥–∞–µ—Ç —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Å–ª–æ–≤–∞—Ä—å platform_data –¥–ª—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è"""
		platform_data = {
			'from_id': self._serialize_peer(getattr(comment, 'from_id', None)),
			'reply_to_msg_id': getattr(comment, 'reply_to_msg_id', None),
			'views': getattr(comment, 'views', 0)
		}
		return platform_data

	def _extract_user_id(self, peer):
		"""–ò–∑–≤–ª–µ–∫–∞–µ—Ç user_id –∏–∑ Peer –æ–±—ä–µ–∫—Ç–∞"""
		if isinstance(peer, PeerUser):
			return str(peer.user_id)
		elif hasattr(peer, 'user_id'):
			return str(peer.user_id)
		elif isinstance(peer, (PeerChannel, PeerChat)):
			return None
		return str(peer)

	async def get_news(self, channels, keywords, days=3):
		"""–ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
		await self.client.start()
		end_date = datetime.now(timezone.utc)
		start_date = end_date - timedelta(days=days)

		print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –ø–æ {len(channels)} –∫–∞–Ω–∞–ª–∞–º")
		print(f"üìã –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords}")
		print(f"‚è∞ –ü–µ—Ä–∏–æ–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π")

		results = []

		with create_app().app_context():
			for channel in channels:
				try:
					print(f"\nüì° –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–Ω–∞–ª: {channel}")
					source = await self._get_or_create_source(channel)
					post_count = 0

					async for message in self.client.iter_messages(channel, limit=100):
						message_date = message.date.replace(
							tzinfo=timezone.utc) if message.date.tzinfo is None else message.date

						if message_date < start_date:
							if post_count > 0:
								print(f"‚è© –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ {channel}")
							break

						if message.text:
							message_text = message.text.lower()
							found_keywords = []

							# –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
							for kw in keywords:
								if kw.lower() in message_text:
									found_keywords.append(kw)

							# –ü–æ–∏—Å–∫ —Ö–µ—à—Ç–µ–≥–æ–≤
							found_hashtags = []
							if hasattr(message, 'entities'):
								for entity in message.entities:
									if hasattr(entity, 'type') and entity.type == 'hashtag':
										hashtag_start = entity.offset
										hashtag_end = hashtag_start + entity.length
										hashtag = message.text[hashtag_start:hashtag_end].lower()
										for kw in keywords:
											if kw.startswith('#') and kw.lower() in hashtag:
												found_hashtags.append(kw)

							if found_keywords or found_hashtags:
								post_count += 1
								print(
									f"‚úÖ –ü–æ—Å—Ç {post_count}: –Ω–∞–π–¥–µ–Ω—ã –∫–ª—é—á–∏ - {found_keywords}, —Ö–µ—à—Ç–µ–≥–∏ - {found_hashtags}")

								post = await self._save_post(source, message, keywords)
								comments = await self._get_comments(channel, message.id, post)

								results.append({
									'date': message_date.strftime('%Y-%m-%d %H:%M'),
									'text': message.text,
									'url': f"https://t.me/{channel}/{message.id}",
									'comments': comments,
									'id': post.id
								})

					print(f"üìä –í –∫–∞–Ω–∞–ª–µ {channel} –Ω–∞–π–¥–µ–Ω–æ {post_count} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ—Å—Ç–æ–≤")

				except Exception as e:
					print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–∞–Ω–∞–ª–µ {channel}: {e}")
					continue

		print(f"\nüéØ –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å—Ç–æ–≤: {len(results)}")
		return sorted(results, key=lambda x: x['date'], reverse=True)

	async def search_by_hashtag(self, channel, hashtag, days=3):
		"""–ò—â–µ—Ç –ø–æ—Å—Ç—ã –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ö–µ—à—Ç–µ–≥—É"""
		await self.client.start()
		end_date = datetime.now(timezone.utc)
		start_date = end_date - timedelta(days=days)

		results = []

		try:
			async for message in self.client.iter_messages(channel, limit=100):
				message_date = message.date.replace(
					tzinfo=timezone.utc) if message.date.tzinfo is None else message.date

				if message_date < start_date:
					break

				if message.text and hasattr(message, 'entities'):
					for entity in message.entities:
						if hasattr(entity, 'type') and entity.type == 'hashtag':
							hashtag_start = entity.offset
							hashtag_end = hashtag_start + entity.length
							message_hashtag = message.text[hashtag_start:hashtag_end].lower()

							if hashtag.lower() in message_hashtag:
								results.append({
									'date': message_date.strftime('%Y-%m-%d %H:%M'),
									'text': message.text,
									'url': f"https://t.me/{channel}/{message.id}"
								})
								break

		except Exception as e:
			print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ —Ö–µ—à—Ç–µ–≥—É {hashtag}: {e}")

		return results


	async def _get_or_create_source(self, channel_name):
		"""–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π"""
		source = NewsSource.query.filter_by(
			platform='telegram',
			source_id=channel_name
		).first()

		if not source:
			source = NewsSource(
				platform='telegram',
				source_id=channel_name,
				source_name=channel_name,
				source_type='channel'
			)
			db.session.add(source)
			db.session.flush()

		return source


	async def _save_post(self, source, message, keywords):
		"""–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å—Ç –≤ –ë–î"""
		post_id_str = str(message.id)

		post = NewsPost.query.filter_by(
			platform='telegram',
			platform_post_id=post_id_str
		).first()

		if not post:
			# –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ
			platform_data = self._serialize_platform_data(message)

			post = NewsPost(
				platform='telegram',
				platform_post_id=post_id_str,
				source_id=source.id,
				text=message.text,
				url=f"https://t.me/{source.source_id}/{message.id}",
				author=source.source_name,
				publish_date=message.date,
				keywords=keywords,
				platform_data=platform_data
			)
			db.session.add(post)
			db.session.flush()

		return post

	async def _get_comments(self, channel, post_id, post):
		"""–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –ø–æ—Å—Ç—É, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ë–î –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –≤ JSON"""
		comments_data = []
		negative_count = 0

		try:
			async for comment in self.client.iter_messages(channel, reply_to=post_id, limit=50):
				if comment and comment.text:
					sentiment = classify_text(comment.text)
					print(f"üìù –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment.text[:50]}... -> {sentiment}")

					# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≤ –ë–î
					saved_comment = await self._save_comment(post, comment, sentiment)

					# –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ JSON
					if sentiment == "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π":
						negative_count += 1
						user_id = self._extract_user_id(getattr(comment, 'from_id', ''))

						bad_comment_data = {
							'platform_comment_id': str(comment.id),
							'post_id': post.id,
							'post_title': post.text[:100] + '...' if post.text else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è',
							'post_url': post.url,
							'text': comment.text,
							'user_id': user_id if user_id else 'unknown',
							'publish_date': comment.date.isoformat(),
							'platform': 'Telegram',
							'sentiment': sentiment,
							'platform_data': {
								'from_id': user_id if user_id else 'unknown',
								'reply_to_msg_id': getattr(comment, 'reply_to_msg_id', None)
							}
						}

						print(f"üî¥ –ù–∞–π–¥–µ–Ω –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π #{negative_count}")

						# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –µ—â–µ –Ω–µ—Ç –≤ JSON
						save_bad_comment(bad_comment_data)

					comments_data.append({
						'date': comment.date.strftime('%H:%M'),
						'text': f"[{sentiment}] {comment.text}",
						'sentiment': sentiment,
						'original_text': comment.text
					})

			print(f"üìä –ò—Ç–æ–≥–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {negative_count}")

		except MsgIdInvalidError:
			print(f"–°–æ–æ–±—â–µ–Ω–∏–µ {post_id} –Ω–µ –∏–º–µ–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ ID –Ω–µ–≤–µ—Ä–Ω—ã–π")
		except Exception as e:
			print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {post_id}: {e}")

		return comments_data
	async def _save_comment(self, post, comment, sentiment):
		"""–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≤ –ë–î"""
		comment_id_str = str(comment.id)
		user_id = self._extract_user_id(getattr(comment, 'from_id', ''))
		user_id_str = user_id if user_id else 'unknown'

		existing_comment = PostComment.query.filter_by(
			post_id=post.id,
			platform_comment_id=comment_id_str
		).first()

		if not existing_comment:
			# –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ platform_data
			platform_data = self._serialize_comment_platform_data(comment)

			new_comment = PostComment(
				post_id=post.id,
				platform_comment_id=comment_id_str,
				platform_user_id=user_id_str,
				text=comment.text,
				sentiment=sentiment,
				publish_date=comment.date,
				likes_count=getattr(comment, 'views', 0) if hasattr(comment, 'views') else 0,
				platform_data=platform_data
			)
			db.session.add(new_comment)
			return new_comment

		return existing_comment

	async def close(self):
		await self.client.disconnect()


async def main():
	# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑
	app = create_app()

	# –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤ —Å–µ—Ä–≤–∏—Å
	service = TelegramService()

	try:
		# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
		with app.app_context():
			keywords = [
				'–¢–ù–°',
				'—ç–Ω–µ—Ä–≥–æ',
				'—ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç',
				'—ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ',
				'—ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ',
			]

			# –î–æ–±–∞–≤—å—Ç–µ —Ö–µ—à—Ç–µ–≥–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
			hashtags = [
				'#–¢–ù–°',
				'#—ç–Ω–µ—Ä–≥–æ',
				'#—ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç',
				'#–¢–ù–°—ç–Ω–µ—Ä–≥–æ',
				'#–¢–ù–°—ç–Ω–µ—Ä–≥–æ–ù–ù'
			]

			# –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Ö–µ—à—Ç–µ–≥–∏
			search_terms = keywords + hashtags

			news = await service.get_news(
				channels=['Dzerzhinsk_blackhole', 'tns_energo_nn'],
				keywords=search_terms,
				days=5
			)

			print(f"–ù–∞–π–¥–µ–Ω–æ {len(news)} –ø–æ—Å—Ç–æ–≤")
			for i, item in enumerate(news[:5], 1):
				print(f"\n{i}. {item['date']}")
				print(f"–¢–µ–∫—Å—Ç: {item['text'][:100]}...")
				print(f"–°—Å—ã–ª–∫–∞: {item['url']}")
				if item['comments']:
					print(f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ ({len(item['comments'])}):")
					for j, comment in enumerate(item['comments'][:3], 1):
						print(f"  {j}. {comment['date']}: {comment['text'][:80]}...")
				else:
					print("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: –Ω–µ—Ç")

	except Exception as e:
		print(f"–û—à–∏–±–∫–∞ –≤ main: {e}")
		import traceback
		traceback.print_exc()
	finally:
		await service.close()


if __name__ == '__main__':
	asyncio.run(main())